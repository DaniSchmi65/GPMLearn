import streamlit as st
import pandas as pd
import random
import openai
import os
import importlib.metadata
from llama_index.core import StorageContext, load_index_from_storage

# ğŸ§ª Zeige LlamaIndex-Version
version = importlib.metadata.version("llama-index")
st.write(f"âœ… LlamaIndex Version: {version}")

# ğŸ” OpenAI API-Key laden
openai.api_key = st.secrets["openai_api_key"]

# ğŸ“„ Fragen aus Excel laden
@st.cache_data
def lade_fragen(pfad):
    df = pd.read_excel(pfad)
    df.columns = ["Frage"]
    return df

fragen_df = lade_fragen("fragen.xlsx")

# ğŸ§  Session State initialisieren
if "richtig" not in st.session_state:
    st.session_state.richtig = 0
if "falsch" not in st.session_state:
    st.session_state.falsch = 0
if "aktuelle_frage" not in st.session_state:
    st.session_state.aktuelle_frage = random.choice(fragen_df["Frage"].tolist())
if "geprÃ¼ft" not in st.session_state:
    st.session_state.geprÃ¼ft = False
if "antwort" not in st.session_state:
    st.session_state.antwort = ""

# ğŸ“¦ Vektorindex laden
try:
    storage_context = StorageContext.from_defaults(persist_dir="index_storage")
    index = load_index_from_storage(storage_context)
    engine = index.as_query_engine(similarity_top_k=3)
except Exception as e:
    st.error(f"âŒ Fehler beim Laden des Index: {e}")
    st.stop()

# ğŸ§  Aktuelle Frage anzeigen
st.title("ğŸ§  GPT-Lerntrainer")
st.subheader("Beantworte die folgende Frage:")
st.markdown(f"**Frage:** {st.session_state.aktuelle_frage}")

# âœï¸ Texteingabe
st.text_area("Deine Antwort:", key="antwort")

# âœ… Antwort prÃ¼fen
if st.button("Antwort prÃ¼fen"):
    with st.spinner("ğŸ” Antwort wird geprÃ¼ft..."):

        st.session_state.geprÃ¼ft = True

        query = f"""
Du bist ein strenger, aber hilfsbereiter Lerncoach.

Frage: {st.session_state.aktuelle_frage}
Antwort des Nutzers: {st.session_state.antwort}

Deine Aufgabe:
1. Bewerte, ob die Antwort korrekt, teilweise korrekt oder falsch ist.
2. Gib konstruktives Feedback zur Antwort â€“ nenne VerbesserungsmÃ¶glichkeiten.
3. Gib eine Beispielantwort, wie sie idealerweise aussehen sollte.
4. Antworte in freundlichem, motivierendem Ton.
"""
        result = engine.query(query)
        response_text = str(result)

        # GPT-Antwort anzeigen
        st.markdown("### ğŸ’¡ GPT RÃ¼ckmeldung:")
        st.write(response_text)

        if "korrekt" in response_text.lower() and "nicht korrekt" not in response_text.lower():
            st.success("âœ… Deine Antwort scheint korrekt oder weitgehend korrekt zu sein.")
            st.session_state.richtig += 1
        else:
            st.warning("âŒ Die Antwort war unvollstÃ¤ndig oder falsch.")
            st.session_state.falsch += 1

# ğŸ“Š Statistik & Steuerung
st.markdown("---")
st.markdown(f"**âœ… Richtig beantwortet:** {st.session_state.richtig}")
st.markdown(f"**âŒ Falsch beantwortet:** {st.session_state.falsch}")

col1, col2 = st.columns(2)

# ğŸ” ZÃ¤hler zurÃ¼cksetzen
with col1:
    if st.button("ğŸ”„ ZÃ¤hler zurÃ¼cksetzen"):
        st.session_state.richtig = 0
        st.session_state.falsch = 0
        st.success("ZÃ¤hler zurÃ¼ckgesetzt.")

# â¡ï¸ Neue Frage
with col2:
    if st.button("â¡ï¸ NÃ¤chste Frage anzeigen"):
        neue_frage = random.choice(fragen_df["Frage"].tolist())
        while neue_frage == st.session_state.aktuelle_frage:
            neue_frage = random.choice(fragen_df["Frage"].tolist())

        # Nur sichere Keys setzen, nicht "antwort" direkt!
        st.session_state.aktuelle_frage = neue_frage
        st.session_state.geprÃ¼ft = False

        # Eingabefeld Ã¼ber Widget-Reset (Trick: force rerun + remove key)
        st.session_state.pop("antwort", None)  # â‡ï¸ sicher entfernen
        st.experimental_rerun()                # ğŸ” alles neu laden

