import streamlit as st
import openai
import pandas as pd
import random

from llama_index import load_index_from_storage
from llama_index.query_engine import RetrieverQueryEngine
from llama_index.storage.storage_context import StorageContext

import os
st.write("ğŸ“‚ index_storage Inhalt:")
st.write(os.listdir("index_storage"))

# ğŸ” OpenAI API-Key laden
openai.api_key = st.secrets["openai_api_key"]

# ğŸ“¦ Vektorindex laden
storage_context = StorageContext.from_defaults(persist_dir="index_storage")
index = load_index_from_storage(storage_context)

# ğŸ” Nur Top 3 passende Abschnitte an GPT weitergeben
query_engine = RetrieverQueryEngine.from_index(index, similarity_top_k=3)

# ğŸ“„ Fragen aus Excel laden
@st.cache_data
def lade_fragen(pfad: str) -> pd.DataFrame:
    df = pd.read_excel(pfad)
    df.columns = ["Frage"]
    return df

fragen_df = lade_fragen("fragen.xlsx")

# ğŸ§  Session State initialisieren
if "richtig" not in st.session_state:
    st.session_state.richtig = 0
if "falsch" not in st.session_state:
    st.session_state.falsch = 0
if "aktuelle_frage" not in st.session_state:
    st.session_state.aktuelle_frage = ""
if "user_antwort" not in st.session_state:
    st.session_state.user_antwort = ""

# ğŸ² Neue zufÃ¤llige Frage
if st.button("ğŸ² Neue Frage"):
    st.session_state.aktuelle_frage = fragen_df.sample(1).iloc[0, 0]
    st.session_state.user_antwort = ""

# ğŸ“‹ Anzeige der aktuellen Frage
st.title("ğŸ“š GPT Lerntrainer")
st.markdown("**Frage:**")
st.markdown(st.session_state.aktuelle_frage)

antwort = st.text_area("âœï¸ Deine Antwort", value=st.session_state.user_antwort, height=150)

# âœ… Antwort prÃ¼fen per GPT
if st.button("âœ… Antwort prÃ¼fen"):
    st.session_state.user_antwort = antwort
    frage = st.session_state.aktuelle_frage

    with st.spinner("GPT denkt nach..."):
        try:
            # Hole Kontext aus PDF-Wissensdatenbank
            context = query_engine.query(frage).response

            prompt = f"""
Du bist ein strenger, aber hilfsbereiter Lerncoach. Vergleiche die folgende Nutzerantwort mit dem relevanten Wissen aus den Studienunterlagen.

Frage: {frage}
Antwort des Nutzers: {antwort}
Relevanter Kontext: {context}

Gib eine prÃ¤zise RÃ¼ckmeldung:
- Ist die Antwort richtig, teilweise richtig oder falsch?
- Was fehlt oder kÃ¶nnte besser sein?
- Optional: Formuliere eine Musterantwort.

Antworte bitte strukturiert.
"""

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
            )

            output = response.choices[0].message.content
            st.markdown("### ğŸ¤– GPT-Feedback:")
            st.markdown(output)

            # ZÃ¤hler erhÃ¶hen (einfaches Matching)
            if "richtig" in output.lower():
                st.session_state.richtig += 1
            else:
                st.session_state.falsch += 1

        except Exception as e:
            st.error(f"Fehler bei der GPT-Anfrage:\n\n{str(e)}")

# ğŸ“Š Auswertung
st.markdown(f"âœ… **Richtig**: {st.session_state.richtig}â€ƒâŒ **Falsch**: {st.session_state.falsch}")
if st.button("ğŸ”„ ZÃ¤hler zurÃ¼cksetzen"):
    st.session_state.richtig = 0
    st.session_state.falsch = 0
